{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8515886-498f-4b8f-a7c5-c3fc3a675a9d",
   "metadata": {},
   "source": [
    "# Getting Started with Groq API\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Groq is an AI solutions delivering ultra-low latency inference with the first-ever LPUâ„¢ Inference Engine. Groq API enables developers to integrate state-of-the-art LLMs such as Llama into low latency applications. Learn more at [groq.com](https://groq.com).\n",
    "\n",
    "## Access and Rate Limits\n",
    "\n",
    "You can free access Groq with rate limits. For more details, visit [Groq Console](https://console.groq.com/settings/limits).\n",
    "\n",
    "## Installation\n",
    "\n",
    "To install the Groq API, run the following command:\n",
    "\n",
    "```bash\n",
    "pip install groq\n",
    "```\n",
    "\n",
    "## Obtain Your API Key\n",
    "\n",
    "To get your API key, visit [Groq Console](https://console.groq.com/keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd0c45c1-9abd-424a-b1e8-d9278d4a4f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b66af88-32d0-4cb8-b993-20d11e939f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "import os\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355f9a24-51ce-4eec-acab-880448ab9464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f427bc4d-e34e-4f41-9915-3ab8ab994bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ['GROQ_API_KEY'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2494a5a-6edb-42d8-a669-c8894034fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa0e43ae-6391-4810-9166-c3a4303b2a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Fast language models have become increasingly important in recent years due to their ability to process and generate human-like text quickly and accurately. Here are some reasons why fast language models are significant:\n",
       "\n",
       "1. **Rapid Development Cycle**: Fast language models enable developers to iterate and refine their applications quickly, reducing the time-to-market for new projects. This enables companies to respond faster to changing market conditions and customer needs.\n",
       "2. **Improved User Experience**: Fast language models can generate responses in real-time, providing a more immersive and engaging user experience for applications such as chatbots, voice assistants, and translation services.\n",
       "3. **Scalability**: Fast language models can handle a large volume of requests, making them suitable for massive-scale applications like customer support platforms, social media, and e-commerce websites.\n",
       "4. **Increased Accuracy**: Fast language models can be trained on vast amounts of data, enabling them to learn from variations in language and improve their accuracy over time.\n",
       "5. **Cost-Effectiveness**: Fast language models can process tasks more efficiently, reducing the computational resources required, which can lead to cost savings for organizations.\n",
       "6. **Advancements in AI Research**: Fast language models have accelerated advancements in AI research, enabling scientists to explore new applications, such as natural language processing, sentiment analysis, and text summarization.\n",
       "7. **Enhanced Conversational AI**: Fast language models can facilitate more natural and human-like conversations, enabling applications like chatbots and virtual assistants to better understand and respond to user queries.\n",
       "8. **Improved Accessibility**: Fast language models can help make language-based services more accessible to people with disabilities, such as those with motor impairments, by providing real-time language translation and text-to-speech capabilities.\n",
       "9. **Business Opportunities**: Fast language models create new business opportunities in industries like customer service, marketing, and education, where accurate and rapid language processing can revolutionize the way companies interact with customers and communicate information.\n",
       "10. **Foundation for Other AI Applications**: Fast language models can serve as a foundation for other AI applications, such as computer vision, robotics, and autonomous vehicles, where natural language processing is essential for effective interaction with humans.\n",
       "\n",
       "In summary, fast language models have the potential to transform various industries and applications, enabling faster, more accurate, and more scalable language processing. Their importance lies in their ability to improve user experiences, drive innovation, and create new business opportunities."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(chat_completion.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "088abf35-5f34-49ad-bcc7-351da3312a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Fast language models have gained significant attention in recent years due to their wide range of applications and benefits. Here are some of the key reasons why fast language models are important:\n",
       "\n",
       "1. **Improved Efficiency**: Fast language models can process and generate text much faster than traditional models, making them suitable for real-time applications where speed is critical.\n",
       "\n",
       "2. **Scalability**: Fast language models can be easily integrated into various industries such as customer service, marketing, and content creation, allowing for faster and more efficient processing of large volumes of data.\n",
       "\n",
       "3. **Increased Responsiveness**: By reducing processing times, fast language models enable businesses to respond to customers faster, improving customer satisfaction and loyalty.\n",
       "\n",
       "4. **Enhanced User Experience**: Fast language models can analyze and generate text in real-time, allowing for a seamless and personalized experience for users.\n",
       "\n",
       "5. **Cost Savings**: With their ability to process text quickly, fast language models can reduce the need for manual processing, resulting in cost savings for businesses.\n",
       "\n",
       "6. **More Accurate Results**: By allowing for faster processing of text data, fast language models can provide more accurate results as they are able to analyze and generate text more quickly and efficiently.\n",
       "\n",
       "7. **Increased Innovation**: Fast language models can be used to explore new applications and use cases, driving innovation and advancements in the field of natural language processing.\n",
       "\n",
       "8. **Improved Human-Machine Interaction**: Fast language models can enable more natural and intuitive human-machine interactions, such as voice assistants and chatbots, which rely on quick and accurate text analysis.\n",
       "\n",
       "9. **Better Customer Insights**: Fast language models can provide businesses with real-time customer insights, enabling them to make data-driven decisions and improve their customer service.\n",
       "\n",
       "10. **Advancements in Fields like NLP**: Fast language models have the potential to push the boundaries of natural language processing, driving advancements in fields like machine translation, text summarization, and sentiment analysis.\n",
       "\n",
       "In summary, fast language models are crucial for various industries and applications where speed and efficiency are essential. Their ability to quickly process and generate text has numerous benefits, including improved performance, cost savings, and enhanced user experience."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with client.chat.completions.with_streaming_response.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        },\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ") as response:\n",
    "\n",
    "    for line in response.iter_lines():\n",
    "        display(Markdown(json.loads(line)['choices'][0]['message']['content']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319e29cb-9cc5-4fdb-8d62-dc3705c3300c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c78727f-f7df-452e-bae0-4da697540ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbb3733-644b-49fc-b8f2-7d8f58ae292a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e06102-805d-480a-86c6-ba9cba24205d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
